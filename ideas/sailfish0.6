#!/usr/bin/env python3


from argparse import ArgumentParser, SUPPRESS
from collections import deque
from collections.abc import Mapping, Iterable
from contextlib import contextmanager
from dataclasses import asdict, dataclass
from itertools import chain, product
from pickle import dump as dump_pickle
from json import load as load_json, dumps as dumps_json
from logging import getLogger
from typing import NamedTuple

from app_config import Sailfish, Driver, Report, Strategy, Scheme, Checkpoint
from new_kernels import perf_time_sequence, configure_kernel_module
from solver import make_solver


@dataclass
class iteration_report:
    """
    Light-weight status of an iteration or group of iterations
    """

    iteration: int
    time: float
    zps: float

    def __repr__(self):
        return (
            f"[{self.iteration:06d}] "
            f"t={self.time:0.5f} "
            f"Mzps={self.zps/1e6:0.3f} "
        )

    def __rich_console__(self, *args):
        yield (
            f"[cyan]{self.iteration:06d}[/cyan] "
            f"[green]t={self.time:0.5f}[/green] "
            f"[magenta]Mzps={self.zps/1e6:0.3f}[/magenta]"
        )


@dataclass
class run_summary:
    """
    Light-weight epilog of a run
    """

    app: Sailfish
    total_sec: float
    mean_zps: float

    def __repr__(self):
        return (
            f"run name: {self.app.name}\n"
            f"total run time: {self.total_sec:0.5f} sec\n"
            f"mean Mzps: {self.mean_zps/1e6:0.3f}"
        )


@dataclass
class event_state:
    number: int
    last_time: float
    action: any = None


def recurring_event(interval: float, last_time: float = None, number: int = 0):
    """
    A generator which yields True or False based on whether a task is due
    """
    is_due = None

    while True:
        time = yield is_due and event_state(number, last_time)

        if time == 0.0:
            is_due = True
            last_time = time

        elif time >= last_time + interval:
            is_due = True
            number += 1
            last_time = last_time + interval

        else:
            is_due = False


def timeseries(app, state, timeseries, event_states):
    number = event_states["timeseries"].number
    time = timeseries.setdefault("time", list())
    time.append(state.time)

    return event_state(
        number=number,
        last_time=state.time,
        action=f"timeseries {state.time}",
    )


def checkpoint(app, state, timeseries, event_states):
    number = event_states["checkpoint"].number
    filename = f"chkpt.{number:04d}.pk"

    with open(filename, "wb") as outf:
        dump_pickle(
            dict(
                app=app,
                state=state.primitive,
                timeseries=timeseries,
                event_states=event_states,
            ),
            outf,
        )

    return event_state(
        number=number,
        last_time=state.time,
        action=f"checkpoint {filename}",
    )


def run(apps: Iterable[Sailfish]):
    """
    Main simulation driver function

    This function drives a sequence of applications
    """
    for app in apps:
        yield app

        configure_kernel_module(default_exec_mode=app.hardware)

        fold = app.driver.report.cadence
        tfinal = app.driver.tfinal
        states = make_solver(app)
        app_timer = perf_time_sequence(mode=app.hardware)
        fld_timer = perf_time_sequence(mode=app.hardware)
        event_states = dict()
        timeseries_data = dict()
        zps_log = [0.0]
        events = dict(
            timeseries=recurring_event(app.driver.timeseries.cadence),
            checkpoint=recurring_event(app.driver.checkpoint.cadence),
        )
        for event in events.values():
            event.send(None)

        state = next(states)

        while True:

            if e := events["timeseries"].send(state.time):
                event_states["timeseries"] = e
                yield timeseries(app, state, timeseries_data, event_states)

            if e := events["checkpoint"].send(state.time):
                event_states["checkpoint"] = e
                yield checkpoint(app, state, timeseries_data, event_states)

            if state.time >= tfinal:
                break

            state = next(states)

            if state.iteration % fold == 0:
                sec = next(fld_timer)
                zps = state.total_zones / sec * fold
                zps_log.append(zps)
                yield iteration_report(state.iteration, state.time, zps)

        yield run_summary(app, next(app_timer), sum(zps_log) / len(zps_log))


def scrollback(print):
    """
    A run monitor that writes run status and iteration reports to the console

    The print function can be builtin, or something else such as rich.print.
    """

    while True:
        event = yield

        if type(event) is Sailfish:
            app = event
            print(app)

        elif type(event) is run_summary:
            summary = event
            print()
            print(summary)
            print()

        elif type(event) is iteration_report:
            report = event
            print(report)

        else:
            print(event)


def reports_table(reports: Iterable[iteration_report]):
    """
    Generate a rich table from a sequence of iteration reports
    """
    from rich.table import Table
    from rich.panel import Panel

    table = Table(expand=True, show_edge=False)
    table.add_column("iteration", style="cyan", justify="right")
    table.add_column("time", style="green")
    table.add_column("zones per second (millions)", style="magenta", justify="left")

    for report in reports:
        table.add_row(
            f"{report.iteration}",
            f"{report.time:0.5f}",
            f"{report.zps/1e6:0.3f}",
        )

    table.add_section()

    if any(reports):
        avg_zps = sum(r.zps for r in reports) / max(1, len(reports))
        table.add_row(None, None, f"{avg_zps/1e6:0.3f}", style="italic")

    return Panel(table, style="dim", border_style="blue", padding=(2, 2))


def summaries_table(summaries: list[run_summary]):
    """
    Generate a rich table from a sequence of run summary reports
    """

    from rich.table import Table
    from rich.panel import Panel

    table = Table(expand=True, show_edge=False)
    table.add_column("run name", style="cyan", justify="left")
    table.add_column("<zones per second> (millions)", style="magenta", justify="left")

    for summary in summaries:
        table.add_row(f"{summary.app.name}", f"{summary.mean_zps/1e6:0.5f}")

    return Panel(table, style="dim", border_style="red", padding=(2, 2))


def dashboard(console, screen=False):
    from rich.live import Live
    from rich.pretty import Pretty
    from rich.progress import Progress
    from rich.layout import Layout
    from rich.panel import Panel

    reports = deque()
    summaries = list()
    progress = Progress()
    app_struct = str()
    job_num = 0

    app_view = Layout(str(), name="app", ratio=5)
    progress_view = Layout(
        Panel(
            progress,
            title="Job Progress",
            padding=(2, 2),
            border_style="green",
        ),
        ratio=3,
        name="progress",
    )
    reports_view = Layout(reports_table(reports), name="reports", ratio=3)
    summaries_view = Layout(summaries_table(reports), name="summaries", ratio=5)

    root = Layout(name="root")
    root.split_column(Layout(name="upper", ratio=2), Layout(name="lower", ratio=3))
    root["upper"].split_row(app_view, progress_view)
    root["lower"].split_row(reports_view, summaries_view)

    with Live(
        root,
        console=console,
        auto_refresh=False,
        screen=screen,
    ) as live:
        while True:
            event = yield

            if type(event) is Sailfish:
                app = event
                job_num += 1
                duration = app.driver.tfinal - app.driver.tstart
                run_task = progress.add_task(f"job {job_num}", total=duration)
                app_view.update(
                    Panel(
                        Pretty(app),
                        title="Run Description",
                        padding=(2, 2),
                        border_style="bright_blue",
                    )
                )

            elif type(event) is iteration_report:
                report = event
                reports.append(report)

                if len(reports) > 20:
                    reports.popleft()

                reports_view.update(reports_table(reports))
                evolved_time = report.time - app.driver.tstart
                progress.update(run_task, completed=evolved_time)

            elif type(event) is run_summary:
                summary = event
                reports = deque()
                summaries.append(summary)
                summaries_view.update(summaries_table(summaries))

            live.refresh()


def parse_num_zones(arg):
    """
    Promote an integer or two-tuple to a three-tuple of integers

    This factory function is used by the argparse type parameter to convert
    user input to a domain.num_zones parameter.
    """
    res = tuple(int(i) for i in arg.split(","))

    if len(res) == 1:
        return res + (1, 1)
    if len(res) == 2:
        return res + (1,)
    if len(res) == 3:
        return res
    raise ValueError(f"invalid argument for num_zones {arg}")


def parse_reconstruction(arg):
    """
    Promote a string to a reconstruction model

    This factory function is used by the argparse type parameter to convert
    user input to a scheme.reconstruction parameter.
    """
    try:
        mode, theta = arg.split(":")
        return mode, float(theta)
    except ValueError:
        if arg == "plm":
            return arg, 1.5
        else:
            return arg


def deep_update(d, u):
    """
    Update a dictionary and any nested dictionaries recursively
    """
    for k, v in u.items():
        if isinstance(v, Mapping):
            d[k] = deep_update(d.get(k, dict()), v)
        else:
            d[k] = v
    return d


def unflatten(d):
    """
    Create a nested dict from a flat one with keys like a.b.c
    """
    res = dict()
    for key, value in d.items():
        parts = key.split(".")
        d = res
        for part in parts[:-1]:
            if part not in d:
                d[part] = dict()
            d = d[part]
        d[parts[-1]] = value
    return res


def init_logging(level):
    from rich.console import Console
    from rich.logging import RichHandler

    console = Console()
    handler = RichHandler(omit_repeated_times=False, console=console)
    logger = getLogger("sailfish")
    logger.addHandler(handler)
    logger.setLevel(level.upper())

    return console


def scan_strategies():
    d = {
        "strategy.data_layout": ("fields-last", "fields-first"),
        "strategy.cache_flux": (True, False),
        "strategy.cache_prim": (True, False),
        "strategy.cache_grad": (True, False),
    }
    for p in product(*d.values()):
        yield unflatten(dict(name=str(p), **dict(zip(d.keys(), p))))


def sailfish_presets():
    return {"scan-strategies": scan_strategies()}


def sailfish(config, overrides):
    """
    Yield a sequence of sailfish app structs from a config

    The config may be the name of a preset, which may then be a dictionary
    or sequence of dictionaries, or it may be a path to a json file
    containing a dictionary or a list of dictionaries.
    """
    presets = sailfish_presets()

    if not config:
        cs = dict()
    elif config in presets:
        cs = presets[config]
    elif config.endswith(".json"):
        with open(config) as infile:
            cs = load_json(infile)
    else:
        raise ValueError("config must be a preset or a json file")

    if type(cs) is dict:
        cs = [cs]

    for c in cs:
        s = asdict(Sailfish())
        deep_update(s, c)
        deep_update(s, overrides)
        yield Sailfish(**s)


def argument_parser():
    """
    Create an argument parser instance for running from the command line
    """
    parser = ArgumentParser(
        prog="sailfish_ui",
        usage=SUPPRESS,
        description="sailfish is a GPU-accelerated astrophysical gasdynamics code",
    )
    parser.add_argument(
        "_configs",
        metavar="configs",
        nargs="*",
        default=[dict()],
    )
    parser.add_argument(
        "--log-level",
        dest="_log_level",
        default="warning",
        choices=("debug", "info", "warning", "error", "critical"),
        help="log messages at and above this severity level",
    )
    parser.add_argument(
        "--dash",
        dest="_dash",
        action="store_true",
        help="show a dashboard instead of a scrollback",
    )
    parser.add_argument(
        "--screen",
        dest="_screen",
        action="store_true",
        help="transient screen in dash mode (better look but disappears after the run)",
    )
    parser.add_argument(
        "--mode",
        "--hardware",
        dest="hardware",
        choices=Sailfish.type_args("hardware"),
        help="execution mode",
    )
    parser.add_argument(
        "-n",
        "--num-zones",
        "--resolution",
        type=parse_num_zones,
        dest="domain.num_zones",
        metavar="N",
    )
    parser.add_argument(
        "-m",
        "--time-integration",
        choices=Scheme.type_args("time_integration"),
        help=Scheme.describe("time_integration"),
        dest="scheme.time_integration",
    )
    parser.add_argument(
        "-r",
        "--reconstruction",
        type=parse_reconstruction,
        help=Scheme.describe("reconstruction"),
        dest="scheme.reconstruction",
        metavar="R",
    )
    parser.add_argument(
        "-e",
        "--tfinal",
        type=float,
        help=Driver.describe("tfinal"),
        dest="driver.tfinal",
        metavar="T",
    )
    parser.add_argument(
        "-f",
        "--fold",
        "--report-cadence",
        type=int,
        help=Report.describe("cadence"),
        dest="driver.report.cadence",
        metavar="F",
    )
    parser.add_argument(
        "--checkpoint",
        "-c",
        type=float,
        dest="driver.checkpoint.cadence",
        metavar="C",
    )
    parser.add_argument(
        "--timeseries",
        "-t",
        type=float,
        dest="driver.timeseries.cadence",
        metavar="T",
    )
    parser.add_argument(
        "--data-layout",
        type=str,
        choices=Strategy.type_args("data_layout"),
        help=Strategy.describe("data_layout"),
        dest="strategy.data_layout",
    )
    parser.add_argument(
        "--cache-prim",
        action="store_true",
        dest="strategy.cache_prim",
        default=None,
    )
    parser.add_argument(
        "--cache-flux",
        action="store_true",
        dest="strategy.cache_flux",
        default=None,
    )
    parser.add_argument(
        "--cache-grad",
        action="store_true",
        dest="strategy.cache_grad",
        default=None,
    )
    return parser


def main():
    """
    Main sailfish entry point and command line interface
    """
    parser = argument_parser()
    args = parser.parse_args()
    console = init_logging(args._log_level)
    overrides = unflatten(
        {k: v for k, v in vars(args).items() if v is not None and k[0] != "_"}
    )
    apps = chain(*(sailfish(cfg, overrides) for cfg in args._configs))

    try:
        if args._dash:
            monitor = dashboard(console, args._screen)
        else:
            monitor = scrollback(console.print)

        next(monitor)

        for event in run(apps):
            monitor.send(event)

    except Exception:
        monitor.close()
        console.print_exception()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print()
        print("ctrl-c interrupt")
